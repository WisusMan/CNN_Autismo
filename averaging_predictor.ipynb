{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea443e66",
   "metadata": {},
   "source": [
    "La función realiza predicciones en todas las imágenes de un directorio especificado (sdir) e imprime los resultados.  \n",
    "Tiene dos modos de funcionamiento. En el modo no_promedio se hace una predicción separada para cada imagen   \n",
    "y se imprime la clase y la probabilidad predichas para cada imagen.  \n",
    "En el modo promediado, se realiza una predicción para cada imagen y se almacenan las probabilidades.  \n",
    "Cuando se han completado las predicciones de todas las imágenes, se suman las probabilidades de cada clase.    \n",
    "La clase con la mayor suma de probabilidades se selecciona como la clase predicha para todas las imágenes.  \n",
    "La clase predicha y su probabilidad promediada se imprimen.  \n",
    "Supongamos que tenemos 10 imágenes de la cara de un mismo niño y queremos predecir si es autista.    \n",
    "Puede obtener 10 predicciones individuales y examinar cada una de ellas. Sin embargo, obtendrá una confianza mucho mayor    \n",
    "utilizando el predictor en el modo de promedio para las 10 imágenes. Por supuesto, se puede predecir con una sola imagen de la cara del niño.  \n",
    "pero obtendrá una confianza mucho mayor si utiliza varias imágenes faciales del niño y utiliza el predictor en el modo de promedio.\n",
    "  \n",
    " Los parámetros de la función son:   \n",
    "  * model_path es la ruta completa al modelo entrenado \n",
    "  * txt_path es la ruta completa al fichero classes.txt generado por el cuaderno autism.ipynb cuando se ejecuta para producir el modelo entrenado.    \n",
    "      El archivo classes.txt tiene la forma class0, class1, ...classN. Para el caso del conjunto de datos autista, el archivo aparece como  \n",
    "      autista,no_autista.\n",
    "  * img_size es un tupple (height, width) que representa la forma de la imagen utilizada para entrenar el modelo.   \n",
    "  * mode es una cadena. Si mode=='ave' el predictor proporciona una única predicción de la clase y la probabilidad de clase. Si mode es cualquier    \n",
    "      otro valor de cadena, el predictor proporciona una predicción individual para cada imagen y devuelve un marco de datos con las columnas  \n",
    "      nombre de archivo, clase, probabilidad. Cada fila del marco de datos contiene el nombre del archivo de imagen, la clase predicha y la probabilidad    \n",
    "      de la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7eba86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5de19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(sdir, model_path, txt_path, img_size,  mode):\n",
    "    with open(txt_path, 'r') as f:\n",
    "        content=f.read() \n",
    "    split=content.split(',')\n",
    "    classes=[split[i] for i in range(len(split))]\n",
    "    num_classes=len(classes) \n",
    "    print(\"Carga del modelo. Puede tardar varios segundos\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print ('Modelo cargado')\n",
    "    flist=sorted(os.listdir(sdir))\n",
    "    print ('prediciendo la clase del ', len(flist), ' archivos en  ', sdir)   \n",
    "    filepaths=[]       \n",
    "    sum_list=[0 for i in range( num_classes )]    \n",
    "    for i, f in enumerate(flist):\n",
    "        fpath=os.path.join(sdir,f)\n",
    "        filepaths.append(fpath)\n",
    "    Fseries=pd.Series(filepaths, name ='filepaths')\n",
    "    df=pd.concat([Fseries], axis=1)\n",
    "    gen=tf.keras.preprocessing.image.ImageDataGenerator().flow_from_dataframe(df, x_col='filepaths', y_col=None, target_size=img_size, class_mode=None, shuffle=False)\n",
    "    preds=model.predict(gen)\n",
    "    cclass=[] # Lista de clases pronosticadas\n",
    "    pclass=[] # Lista de probabilidades de clase   \n",
    "    for i, p in enumerate(preds):   # Iterar a través de las predicciones     \n",
    "        for  j, cp in enumerate(p): # Actualizar la lista_suma añadiendo las probabilidades de cada clase\n",
    "            sum_list[j] +=cp        \n",
    "        index=np.argmax(p) # Encontrar el índice del valor en p que tiene la probabilidad más alta\n",
    "        klass=classes[index] # Obtener la clase con mayor probabilidad\n",
    "        cclass.append(klass)\n",
    "        pclass.append(p[index]* 100)\n",
    "    Pseries=pd.Series(pclass, name='% Probability')\n",
    "    Cseries=pd.Series(cclass, name='Predicted Class')\n",
    "    Fseries=pd.Series(flist, name='Filename')                                                                          \n",
    "    pdf=pd.concat([Fseries, Cseries, Pseries], axis=1)  # marco de datos del form Filename, Predicted Class, % Probability      \n",
    "    ave_index=np.argmax(sum_list)\n",
    "    ave_class=classes[ave_index]    \n",
    "    ave_p=sum_list[ave_index]* 100/len(flist)    \n",
    "    if mode == 'ave':\n",
    "        print (f'The class prediction for all images is {ave_class} with a probability of {ave_p:6.2f} %')\n",
    "        return ave_class, ave_p                                             \n",
    "    else:\n",
    "        print (pdf)\n",
    "        return pdf                                                                   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823f2994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model. This may take several seconds\n",
      "model is loaded\n",
      "predicting the class of the  5  files in  C:\\Temp\\Autism\\tests_non_autistic\n",
      "Found 5 validated image filenames.\n",
      "  Filename Predicted Class  % Probability\n",
      "0  006.jpg    non_autistic      90.747321\n",
      "1  007.jpg    non_autistic      99.004108\n",
      "2  008.jpg    non_autistic      87.127084\n",
      "3  009.jpg        autistic      99.136752\n",
      "4  010.jpg    non_autistic      99.059314\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo en modo no promediado: se realizan predicciones individuales y se devuelve un marco de datos\n",
    "txt_path=r'C:\\Temp\\Autism\\classes.txt'\n",
    "sdir=r'C:\\Temp\\Autism\\tests_non_autistic'\n",
    "img_size=(200,200)\n",
    "mode=''\n",
    "model_path=r'C:\\Temp\\Autism\\EfficientNetB5-Autism-92.00.h5'\n",
    "df= predictor(sdir, model_path, txt_path, img_size, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a652c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model. This may take several seconds\n",
      "model is loaded\n",
      "predicting the class of the  5  files in  C:\\Temp\\Autism\\tests_non_autistic\n",
      "Found 5 validated image filenames.\n",
      "The class prediction for all images is non_autistic with a probability of  75.36 %\n"
     ]
    }
   ],
   "source": [
    "# example on same data of averaging mode - 1 prediction is made for all images. returns the predicted class and its probability\n",
    "mode='ave'\n",
    "ave_class, ave_p  =predictor(sdir, model_path, txt_path, img_size,  mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55404f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
